import random
import matplotlib.pyplot as plt
import numpy as np
from operator import itemgetter

def explore_exploit(q,t,averaging_constant=500):
    gaps, i = np.array([]), 0
    while i < 49:
        gaps = np.append(gaps,i**2)
        i += 1
    gaps = np.true_divide(gaps,10000)
    true_u1 = .5
    regret_q = []
    for gap in gaps:
        true_u2 = true_u1 + gap
        regrets = 0
        for i in range(averaging_constant):
            #explore
                # total successes of q trials with p of success true_u1/true_u2
            explore_pulls_1 = np.random.binomial(q,true_u1)
            explore_pulls_2 = np.random.binomial(q,true_u2)
            sample_mean_1 = explore_pulls_1/q
            sample_mean_2 = explore_pulls_2/q
            #exploit
                # successes using remaining pulls on better arm
            est_better_arm = true_u1 if sample_mean_1 > sample_mean_2 else true_u2
            remaining_pulls = t-2*q
            exploit_pulls = np.random.binomial(remaining_pulls,est_better_arm)
            # online_strategy = explore_pulls_1 + explore_pulls_2 + exploit_pulls
            online_strategy = explore_pulls_1 + explore_pulls_2 + (t-2*q)*est_better_arm
            # online_strategy = q*true_u1 + q*true_u2 + (t-2*q)*est_better_arm
            # optimal_strategy = exploit_pulls + 2*max(explore_pulls_1,explore_pulls_2)
            optimal_strategy = t*max(true_u1,true_u2)
            regret = (optimal_strategy - online_strategy)
            regrets += regret
        regret_q.append(regrets/averaging_constant)
    return max(regret_q)

def get_best_q(t):
    qs = np.arange(1, t//16, 50)
    regrets = [(explore_exploit(q,t)) for q in qs]
    min_regret_index = min(enumerate(regrets), key=itemgetter(1))[0]
    return qs[min_regret_index]

def get_q_for_ts(ts):
    qs = []
    for t in ts:
      qs.append(get_best_q(t))
    return qs
